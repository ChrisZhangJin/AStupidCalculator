{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **What is AStupidCalculator**\n",
    "\n",
    "This is just a simple calculator with less functionalities, but all of its functionalities are not implemented by the formular rules but by a RNN network\n",
    "\n",
    "I use a RNN network to fit the basic function of adding, which seems no sence. Because the addition is quite simple, but i use a lots of matrix opertions that consists adding and multiplying to implement the \"add\".\n",
    "\n",
    "The purpose of it is to do a simple tutorial for building a RNN network, and the idea of it is quite simple.  Given an expression of string, like \"1+1\", and the network of calculator outputs \"2\".\n",
    "\n",
    "I only train the network for addition within ten, therefore it's \"stupid\". however i think it is a good example for building the RNN network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **The network**\n",
    " \n",
    "it's a kind of \"translation\" job. Give one string and translate into another string, although it is actual an adding opertion.\n",
    "\n",
    "For the reference of \"translation tutorial\", you can view this post https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "Similar with the post above introduced, i build 2 RNNs. one is encoder and other one is decoder.\n",
    "\n",
    "The EncoderRNN is composed of 1 layers, that is a GRU. right simple, right? but it can work. \n",
    "\n",
    "Look through the code here,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size=1, num_layer=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layer = num_layer\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        '''\n",
    "\n",
    "        :param input:  shape [Batch size, Sequence size, embedding size]\n",
    "        :param hidden: shape [Batch size, Layer size, hidden size]\n",
    "        :return:\n",
    "        '''\n",
    "        if len(input.shape) != 3:\n",
    "            raise ValueError(f'input shape {input.shape} is not in the format [batch, seq, embedding]')\n",
    "\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layer, self.batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EncoderRNN reads the tensor of source string, e.g \"1+1\", and generates the hidden state vector using GRU.\n",
    "\n",
    "Notice the output from the EncoderRNN is dropped. Usually the ouput is taken as Context Vector, but i didn't use it in this task.\n",
    "\n",
    "The decoder is named DecoderRNN, a bit complecated, which is composed by a GRU layer nad Linear layer.\n",
    "\n",
    "\n",
    "\n",
    "|-----------------------------------|\n",
    "|            Relu                   |\n",
    "|-----------------------------------|\n",
    "              |\n",
    "              |\n",
    "              ▼\n",
    "|-----------------------------------|\n",
    "|            GRU                    |\n",
    "|-----------------------------------|\n",
    "              |\n",
    "              |\n",
    "              ▼\n",
    "|-----------------------------------|\n",
    "|            Linear                 |\n",
    "|-----------------------------------|\n",
    "\n",
    "\n",
    "Here is the code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, batch_size=1, num_layer=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layer = num_layer\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        '''\n",
    "\n",
    "        :param input: shape [batch size, sequence size, input size]\n",
    "        :param hidden:  shape [batch size, num layer, hidden size]\n",
    "        :return:shape [batch size, sequence size, output size]\n",
    "        '''\n",
    "        output = F.relu(input)\n",
    "        # output shape: [batch size, sequence size, hidden size]\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layer, self.batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **The training data**\n",
    " \n",
    " \n",
    " the data for training is easy to obtain, i just write a loop for all the expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_table = []\n",
    "for a in range(10):\n",
    "    for b in range(10):\n",
    "        formula_table.append(f'{a}+{b}={a + b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i only train for the addition within ten, so that's all the data i need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **data preprocess**\n",
    " \n",
    " I need to convert the textaul data into vector data that the network can be fed.\n",
    " \n",
    " There are 2 ways to represent the data, char by char or word by word. \n",
    " \n",
    " Let's look at the example \"10+1\", if dividing by char, it will get \"1\", \"0\", \"+\", \"1\"; or it will get \"10\", \"+\", \"1\" while dividing by word.  I think both can work, and i choose the first.\n",
    " \n",
    " \n",
    "**2 invisible Char**\n",
    "Add SOS(Start of String) and EOS(End of String) for the complition. Each string starts from SOS and ends by EOS.\n",
    "\n",
    "By adding these 2 invisible chars, the network will be learning how to start a string and when to end while generating output.\n",
    " \n",
    " \n",
    " |---|      |---|       |---|       |---|       |---|       |---|\n",
    " |SOS|      | 1 |       | 0 |       | + |       | 1 |       |EOS|\n",
    " |---|      |---|       |---|       |---|       |---|       |---|\n",
    " \n",
    " \n",
    " Capsulate all the preprocess in the class ExpressionDataset, derived from torch.utils.data.Dataset, which provides the data, label pair for training and evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(ExpressionDataset, self).__init__()\n",
    "        formula_table = []\n",
    "        self.expression_list = []\n",
    "        self.label_list = []\n",
    "\n",
    "        for a in range(10):\n",
    "            for b in range(10):\n",
    "                formula_table.append(f'{a}+{b}={a + b}')\n",
    "        self.len = len(formula_table)\n",
    "\n",
    "        chars = set(''.join(formula_table))\n",
    "        self.int2char = dict(enumerate(chars, start=2))\n",
    "        self.int2char[0] = 'SOS'  # START OF STRING\n",
    "        self.int2char[1] = 'EOS'  # END OF STRING\n",
    "        self.char2int = {char: ind for ind, char in self.int2char.items()}\n",
    "\n",
    "        for line in formula_table:\n",
    "            pieces = line.split('=')\n",
    "            self.expression_list.append(pieces[0])\n",
    "            self.label_list.append(pieces[1])\n",
    "\n",
    "        self.expression_list_maxlen = len(max(self.expression_list, key=len))\n",
    "        self.label_list_maxlen = len(max(self.label_list, key=len))\n",
    "        print(\"The longest expression has {} characters; The longest label has {} characters\".format(\n",
    "            self.expression_list_maxlen,\n",
    "            self.label_list_maxlen))\n",
    "        # padding with space\n",
    "        for i in range(len(self.expression_list)):\n",
    "            while len(self.expression_list[i]) < self.expression_list_maxlen:\n",
    "                self.expression_list[i] += ' '\n",
    "\n",
    "        for i in range(len(self.label_list)):\n",
    "            while len(self.label_list[i]) < self.label_list_maxlen:\n",
    "                self.label_list[i] += ' '\n",
    "\n",
    "        # print(self.expression_list)\n",
    "        # print(self.label_list)\n",
    "\n",
    "        # encoding character into index array\n",
    "        for i in range(len(self.expression_list)):\n",
    "            self.expression_list[i] = [0, *[1 if c == ' ' else self.char2int[c] for c in self.expression_list[i]], 1]\n",
    "        self.expression_list_maxlen += 2\n",
    "\n",
    "        for i in range(len(self.label_list)):\n",
    "            # -100 will be ignored by CrossEntropyLoss\n",
    "            self.label_list[i] = [0, *[-100 if c == ' ' else self.char2int[c] for c in self.label_list[i]], -100]\n",
    "        for i in range(len(self.label_list)):\n",
    "            for j in range(len(self.label_list[i])):\n",
    "                if self.label_list[i][j] == -100:\n",
    "                    # set the first -100 as EOS(1) and break\n",
    "                    self.label_list[i][j] = 1\n",
    "                    break\n",
    "        self.label_list_maxlen += 2\n",
    "\n",
    "        print('encoding character into index array!')\n",
    "        print(self.expression_list)\n",
    "        print(self.label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding Layer**\n",
    "\n",
    "the Char needs to be embedded to vectors, therefore i set the embedding layer for it.\n",
    "\n",
    "pytorch provides nn.Embedding for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, embedding_size, embedding, ignore_index=- 100):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        self.embedding_size = embedding_size\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "\n",
    "        :param input: shape [batch_size, sequence size]\n",
    "        :return:  shape [batch_size, sequence size, embedding size]\n",
    "        '''\n",
    "        batch_size = input.shape[0]\n",
    "        seq_size = input.shape[1]\n",
    "        out = torch.zeros(batch_size, seq_size, self.embedding_size)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_size):\n",
    "                if self.ignore_index == input[i][j]:\n",
    "                    out[i][j] = self.embedding(torch.LongTensor([1]))\n",
    "                else:\n",
    "                    out[i][j] = self.embedding(input[i][j])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trainer**\n",
    "\n",
    "The trainer implements the concrete training process.\n",
    "\n",
    "**padding the sequence length**\n",
    "\n",
    "The most challenge is the batch training part. the sequences have different length, need to pad the shorter ones based on the longest sequence.\n",
    "\n",
    "In my case, the longest case is \"10+10\", which length is 5, excluding SOS and EOS.\n",
    "\n",
    "Let's take \"1+1\" to do the padding.\n",
    "\n",
    "Its length is 3, and there is 2-char gap. i pad it with space like this. \"1+1  \", there are 2 spaces followed behind the end.\n",
    "\n",
    "In the embedding vector, the space will be converted to EOS directly.\n",
    "\n",
    "\n",
    "**batch training**\n",
    "\n",
    "I use torch.utils.data.DataLoader for the data loading, but if the batch size is not divisible, it will raise shape error when training.\n",
    "\n",
    "Here I defined pad_collate_fn for fixing this issue. The logic goes like this,\n",
    "\n",
    "If the \"batch\" list is less than batch_size, copy the last item of data and add it until it's length matches the size.\n",
    "\n",
    "\n",
    "**Train for DecoderRNN**\n",
    "\n",
    "The traning of EncoderRNN is simple, but for DecoderRNN is not.\n",
    "\n",
    "The DecoderRNN starts from \"SOS\", and it will generate the next char. \n",
    "\n",
    "Let's say we input \"1+10\" and expect Encoder will generate 11 char by char.\n",
    "\n",
    "the step goes like this,\n",
    "\n",
    "Firstly, we initialize it with SOS and hidden_state from Encoder.\n",
    "\n",
    "\n",
    "|-----------------------------------|\n",
    "|            hidden_state           |\n",
    "|-----------------------------------|\n",
    "\n",
    "              |\n",
    "              |\n",
    "              ▼\n",
    "\n",
    "            |---| \n",
    "            |SOS| \n",
    "            |---| \n",
    " \n",
    " Secondly, Decoder generates the next char \"1\" (might not be \"1\") and hidden_state, and feed this hidden_state and output agian.\n",
    " \n",
    "|-----------------------------------|\n",
    "|            hidden_state           |\n",
    "|-----------------------------------|\n",
    "\n",
    "                          |\n",
    "                          |\n",
    "                          ▼\n",
    "\n",
    "            |---|       |---|\n",
    "            |SOS|  ---> | 1 |\n",
    "            |---|       |---|\n",
    "\n",
    "Lastly, repeat this step until getting EOS.\n",
    "\n",
    "\n",
    "|-----------------------------------|\n",
    "|            hidden_state           |\n",
    "|-----------------------------------|\n",
    "\n",
    "                          |\n",
    "                          |\n",
    "                          ▼\n",
    "\n",
    "            |---|       |---|       |---|      |---|\n",
    "            |SOS|  ---> | 1 |  ---> | 1 | ---> |EOS|\n",
    "            |---|       |---|       |---|      |---|\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    '''\n",
    "\n",
    "    :param batch: batch (List[e, l]):\n",
    "    :return:\n",
    "    '''\n",
    "    if len(batch) != batch_size:\n",
    "        n = batch_size - len(batch)\n",
    "        last_one = batch[-1]\n",
    "        for i in range(n):\n",
    "            batch.append(last_one)\n",
    "\n",
    "    seq_index_vectors, label_vectors = zip(\n",
    "        *batch\n",
    "    )\n",
    "    return torch.stack(seq_index_vectors), torch.stack(label_vectors)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, ds, embedding_layer, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "        self.ds = ds\n",
    "        self.dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn)\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.encoder_optimizer = encoder_optimizer\n",
    "        self.decoder_optimizer = decoder_optimizer\n",
    "        self.criterion = criterion\n",
    "        self.latest_acc = 0.\n",
    "\n",
    "    def train_epoch(self, teacher_forcing_ratio):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        for input, target in self.dataloader:\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            # convert np array into torch Tensor\n",
    "            input_tensor = torch.LongTensor(input)\n",
    "            embedded_input = self.embedding_layer(input_tensor)\n",
    "            target_tensor = torch.LongTensor(target)\n",
    "\n",
    "            encoder_hidden = encoder.init_hidden()\n",
    "            encoder_output, encoder_hidden = encoder(embedded_input, encoder_hidden)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "            # shape [batch_size, embedding_size]\n",
    "            decoder_input = self.embedding_layer(torch.zeros(batch_size, 1, dtype=torch.long))\n",
    "\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            if use_teacher_forcing:\n",
    "                for di in range(ds.label_list_maxlen):\n",
    "                    decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                    loss += self.criterion(decoder_output.squeeze(1), target_tensor[:, di])\n",
    "                    decoder_input = self.embedding_layer(target_tensor[:, di].unsqueeze(1))\n",
    "            else:\n",
    "                for di in range(ds.label_list_maxlen):\n",
    "                    decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                    topv, topi = decoder_output.topk(1)\n",
    "                    decoder_input = self.embedding_layer(\n",
    "                        topi.squeeze(1).long().detach())  # detach from history as input\n",
    "                    # squeeze the seq dimension\n",
    "                    loss += self.criterion(decoder_output.squeeze(1), target_tensor[:, di])\n",
    "\n",
    "            print('loss: ', loss.item())\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "    def evaluate(self, print_log=False):\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = len(ds.expression_list)\n",
    "            for e, l in zip(ds.expression_list, ds.label_list):\n",
    "                input = ['' if i == 0 or i == 1 or i == -100 else ds.int2char[i] for i in e]\n",
    "                input = ''.join(input)\n",
    "                label = ['' if i == 0 or i == 1 or i == -100 else ds.int2char[i] for i in l]\n",
    "                label = ''.join(label)\n",
    "\n",
    "                output = trainer.predict(input)\n",
    "                output = ''.join(output)\n",
    "\n",
    "                if print_log is True:\n",
    "                    print(f'{input}={output} \\t\\t\\t\\t', '√' if output == label else 'x')\n",
    "\n",
    "                if output == label:\n",
    "                    correct += 1\n",
    "\n",
    "            acc = correct / total\n",
    "            self.latest_acc = acc\n",
    "            print('[epoch %d ]total accuracy %.4f, encoder optim lr:%.4f, decoder optim lr:%.4f' % (\n",
    "                epoch, acc, self.encoder_optimizer.param_groups[0][\"lr\"], self.decoder_optimizer.param_groups[0][\"lr\"]))\n",
    "            return acc\n",
    "\n",
    "    def predict(self, text):\n",
    "        with torch.no_grad():\n",
    "            # encoding character into index array\n",
    "            text_index = [0, *[1 if c == ' ' else self.ds.char2int[c] for c in text], 1]\n",
    "\n",
    "            input_tensor = torch.LongTensor(text_index).view(1, -1).repeat(batch_size, 1)\n",
    "            embedded_input = self.embedding_layer(input_tensor)\n",
    "\n",
    "            encoder_hidden = encoder.init_hidden()\n",
    "            encoder_output, encoder_hidden = encoder(embedded_input, encoder_hidden)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "            decoder_input = self.embedding_layer(torch.zeros(batch_size, 1, dtype=torch.long))\n",
    "\n",
    "            output_index_list = []\n",
    "            for di in range(20):\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "\n",
    "                output_index = topi.squeeze(1).long().detach()\n",
    "                output_index_list.append(output_index[0].squeeze().item())\n",
    "                decoder_input = self.embedding_layer(output_index)  # detach from history as input\n",
    "\n",
    "                if output_index[0].squeeze().item() == 1:\n",
    "                    break\n",
    "\n",
    "            return ['' if i == 0 or i == 1 else ds.int2char[i] for i in output_index_list]\n",
    "\n",
    "    def save_checkpoint(self, epoch, path='.'):\n",
    "        path = os.path.join(path, 'checkpoint')\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        filename = uuid.uuid4().hex[:10]\n",
    "        filepath = os.path.join(path, '{0}_epoch{1}_acc{2}.pt'.format(filename, epoch, int(self.latest_acc * 100)))\n",
    "\n",
    "        torch.save({\n",
    "            'encoder_state_dict': self.encoder.state_dict(),\n",
    "            'encoder_optim_state_dict': self.encoder_optimizer.state_dict(),\n",
    "            'decoder_state_dict': self.decoder.state_dict(),\n",
    "            'decoder_optim_state_dict': self.decoder_optimizer.state_dict()\n",
    "        }, filepath)\n",
    "\n",
    "        pfilepath = os.path.join(path,\n",
    "                                 '{0}_epoch{1}_acc{2}_params.txt'.format(filename, epoch, int(self.latest_acc * 100)))\n",
    "        with open(pfilepath, 'w') as f:\n",
    "            f.write(f'embedding_size={embedding_size}\\n')\n",
    "            f.write(f'hidden_size={hidden_size}\\n')\n",
    "            f.write(f'batch_size={batch_size}\\n')\n",
    "            f.write('teacher_forcing_ratio=%.4f\\n' % teacher_forcing_ratio)\n",
    "            f.write(f'init lr={lr}\\n')\n",
    "            f.write(f'encoder_optimizer lr={self.encoder_optimizer.param_groups[0][\"lr\"]}\\n')\n",
    "            f.write(f'decoder_optimizer lr={self.decoder_optimizer.param_groups[0][\"lr\"]}\\n')\n",
    "            f.write(f'accuracy={self.latest_acc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function as followed,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        opts, args = getopt.getopt(sys.argv[1:], \"e:h:l:t:b:\",\n",
    "                                   [\"embedding_size=\", \"hidden_size=\", \"learning_rate=\", \"teacher_forcing_ratio=\",\n",
    "                                    \"batch_size=\"])\n",
    "    except getopt.GetoptError:\n",
    "        usage()\n",
    "        sys.exit(2)\n",
    "\n",
    "    for opt, arg in opts:\n",
    "        if opt in (\"-e\", \"--embedding_size\"):\n",
    "            embedding_size = int(arg)\n",
    "        elif opt in (\"-h\", \"--hidden_size\"):\n",
    "            hidden_size = int(arg)\n",
    "        elif opt in (\"-b\", \"--batch_size\"):\n",
    "            batch_size = int(arg)\n",
    "        elif opt in (\"-l\", \"--learning_rate\"):\n",
    "            lr = float(arg)\n",
    "        elif opt in (\"-t\", \"--teacher_forcing_ratio\"):\n",
    "            teacher_forcing_ratio = float(arg)\n",
    "    print('---------------------')\n",
    "    print(f'embedding_size={embedding_size}')\n",
    "    print(f'hidden_size=   {hidden_size}')\n",
    "    print(f'init lr=       {lr}')\n",
    "    print(f'teacher_forcing_ratio={teacher_forcing_ratio}')\n",
    "    print(f'batch_size=    {batch_size}')\n",
    "    print('---------------------')\n",
    "    ds = ExpressionDataset()\n",
    "    dict_size = ds.get_char_count()\n",
    "\n",
    "    embedding = nn.Embedding(dict_size, embedding_size)\n",
    "    embedding_layer = EmbeddingLayer(embedding_size=embedding_size, embedding=embedding)\n",
    "    encoder = EncoderRNN(input_size=embedding_size, hidden_size=hidden_size, batch_size=batch_size)\n",
    "    decoder = DecoderRNN(input_size=embedding_size, output_size=dict_size, hidden_size=hidden_size,\n",
    "                         batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "    encoder_scheduler = StepLR(encoder_optimizer, step_size=2, gamma=0.95)\n",
    "    decoder_scheduler = StepLR(decoder_optimizer, step_size=2, gamma=0.95)\n",
    "\n",
    "    trainer = Trainer(ds, embedding_layer, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    n_epochs = 200\n",
    "    no_improvement = 0\n",
    "    early_stop = 10\n",
    "    best_acc = 0.\n",
    "    epoch = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print('======epoch ', epoch)\n",
    "        if epoch > 5 and epoch % 2 == 0 and teacher_forcing_ratio > 0.05:\n",
    "            teacher_forcing_ratio -= 0.01 * epoch / 10\n",
    "            print(f'teacher_forcing_ratio={teacher_forcing_ratio}')\n",
    "        trainer.train_epoch(teacher_forcing_ratio)\n",
    "        acc = trainer.evaluate()\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            no_improvement = 0\n",
    "\n",
    "            if epoch > 5:\n",
    "                encoder_scheduler.step()\n",
    "                decoder_scheduler.step()\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            print('no improvement: ', no_improvement)\n",
    "\n",
    "            if acc > 0.9:\n",
    "                encoder_scheduler.step()\n",
    "                decoder_scheduler.step()\n",
    "\n",
    "        if no_improvement == early_stop:\n",
    "            print('early stop due to no improvement!')\n",
    "            break\n",
    "\n",
    "    trainer.save_checkpoint(epoch)\n",
    "\n",
    "    print('end training!')\n",
    "    trainer.evaluate(print_log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
